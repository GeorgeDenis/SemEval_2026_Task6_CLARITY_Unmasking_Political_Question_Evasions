{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229ef44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6fa439b-c133-44d4-9ecb-9faf7f42c5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113bc8065a0a42f39903ebabd67be620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f020ec9db6834bc99627f21511b7f9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/3.90M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f06e27da1e1412ea25b144fed824d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/259k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1891923db34bcbadb92d0df7750213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c932050780854ef8805598f57cbd8b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3448 Test: 308\n",
      "Columns: ['title', 'date', 'president', 'url', 'question_order', 'interview_question', 'interview_answer', 'gpt3.5_summary', 'gpt3.5_prediction', 'question', 'annotator_id', 'annotator1', 'annotator2', 'annotator3', 'inaudible', 'multiple_questions', 'affirmative_questions', 'index', 'clarity_label', 'evasion_label']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'title': Value('string'),\n",
       " 'date': Value('string'),\n",
       " 'president': Value('string'),\n",
       " 'url': Value('string'),\n",
       " 'question_order': Value('int64'),\n",
       " 'interview_question': Value('string'),\n",
       " 'interview_answer': Value('string'),\n",
       " 'gpt3.5_summary': Value('string'),\n",
       " 'gpt3.5_prediction': Value('string'),\n",
       " 'question': Value('string'),\n",
       " 'annotator_id': Value('string'),\n",
       " 'annotator1': Value('string'),\n",
       " 'annotator2': Value('string'),\n",
       " 'annotator3': Value('string'),\n",
       " 'inaudible': Value('bool'),\n",
       " 'multiple_questions': Value('bool'),\n",
       " 'affirmative_questions': Value('bool'),\n",
       " 'index': Value('int64'),\n",
       " 'clarity_label': Value('string'),\n",
       " 'evasion_label': Value('string')}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "ds = load_dataset(\"ailsntua/QEvasion\")\n",
    "train = ds[\"train\"]\n",
    "test  = ds[\"test\"]\n",
    "\n",
    "print(\"Train:\", len(train), \"Test:\", len(test))\n",
    "print(\"Columns:\", train.column_names)\n",
    "train.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf4c64d7-c592-4a20-85bb-f610d802109b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3448 Test: 308\n",
      "Columns: ['title', 'date', 'president', 'url', 'question_order', 'interview_question', 'interview_answer', 'gpt3.5_summary', 'gpt3.5_prediction', 'question', 'annotator_id', 'annotator1', 'annotator2', 'annotator3', 'inaudible', 'multiple_questions', 'affirmative_questions', 'index', 'clarity_label', 'evasion_label']\n",
      "Unique clarity labels (train): ['Ambivalent', 'Clear Non-Reply', 'Clear Reply']\n",
      "Unique clarity labels (test): ['Ambivalent', 'Clear Non-Reply', 'Clear Reply']\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", len(train), \"Test:\", len(test))\n",
    "print(\"Columns:\", train.column_names)\n",
    "\n",
    "print(\"Unique clarity labels (train):\", sorted(set(train[\"clarity_label\"])))\n",
    "print(\"Unique clarity labels (test):\",  sorted(set(test[\"clarity_label\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ca8ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f31b0771-da0b-4497-8cf5-96b9418f8ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "TARGET_LABELS = [\"Clear Reply\", \"Ambivalent\", \"Clear Non-Reply\"]\n",
    "\n",
    "def build_prompt(question, answer):\n",
    "    \"\"\"\n",
    "    Build a strict classification prompt for response clarity.\n",
    "    We force the model to output exactly one label so we can parse it reliably.\n",
    "    \"\"\"\n",
    "    return f\"\"\"You are an expert political discourse analyst.\n",
    "\n",
    "Task: classify the clarity of a politician's answer to the given question.\n",
    "\n",
    "Labels:\n",
    "- Clear Reply: directly answers the question unambiguously.\n",
    "- Ambivalent: appears relevant but is vague/hedged/multi-interpretable or partially answers.\n",
    "- Clear Non-Reply: refuses to answer or does not address the question.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "{answer}\n",
    "\n",
    "Return ONLY one label from:\n",
    "Clear Reply, Ambivalent Reply, Clear Non-Reply\n",
    "\"\"\"\n",
    "\n",
    "def call_llm(prompt, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    Calls the LLM using OpenAI API.\n",
    "    Note: Responses API requires max_output_tokens >= 16.\n",
    "    \"\"\"\n",
    "    r = client.responses.create(\n",
    "        model=model,\n",
    "        input=prompt,\n",
    "        temperature=0,\n",
    "        max_output_tokens=16\n",
    "    )\n",
    "    return r.output_text.strip()\n",
    "\n",
    "def normalize_label(raw_text):\n",
    "    \"\"\"\n",
    "    Normalize model output into one of the target labels.\n",
    "    Returns None if parsing fails.\n",
    "    \"\"\"\n",
    "    if raw_text is None:\n",
    "        return None\n",
    "\n",
    "    # take first line, strip punctuation/junk\n",
    "    t = raw_text.splitlines()[0].strip()\n",
    "    t = re.sub(r\"[^A-Za-z \\-]\", \"\", t).strip()\n",
    "\n",
    "    # tolerant matching\n",
    "    if \"Clear Non\" in t:\n",
    "        return \"Clear Non-Reply\"\n",
    "    if \"Clear Reply\" in t:\n",
    "        return \"Clear Reply\"\n",
    "    if \"Ambivalent\" in t:\n",
    "        return \"Ambivalent\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "504ca6de-d892-42a5-a2b2-b92a0fda6f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 0 ---\n",
      "GOLD: Ambivalent\n",
      "RAW : Ambivalent\n",
      "PRED: Ambivalent\n",
      "\n",
      "--- Example 1 ---\n",
      "GOLD: Ambivalent\n",
      "RAW : Ambivalent\n",
      "PRED: Ambivalent\n",
      "\n",
      "--- Example 2 ---\n",
      "GOLD: Ambivalent\n",
      "RAW : Ambivalent\n",
      "PRED: Ambivalent\n",
      "\n",
      "--- Example 3 ---\n",
      "GOLD: Ambivalent\n",
      "RAW : Ambivalent\n",
      "PRED: Ambivalent\n",
      "\n",
      "--- Example 4 ---\n",
      "GOLD: Ambivalent\n",
      "RAW : Ambivalent\n",
      "PRED: Ambivalent\n",
      "\n",
      "--- Example 5 ---\n",
      "GOLD: Ambivalent\n",
      "RAW : Clear Non-Reply\n",
      "PRED: Clear Non-Reply\n",
      "\n",
      "--- Example 6 ---\n",
      "GOLD: Ambivalent\n",
      "RAW : Ambivalent\n",
      "PRED: Ambivalent\n",
      "\n",
      "--- Example 7 ---\n",
      "GOLD: Ambivalent\n",
      "RAW : Ambivalent\n",
      "PRED: Ambivalent\n",
      "\n",
      "--- Example 8 ---\n",
      "GOLD: Ambivalent\n",
      "RAW : Ambivalent\n",
      "PRED: Ambivalent\n",
      "\n",
      "--- Example 9 ---\n",
      "GOLD: Ambivalent\n",
      "RAW : Ambivalent\n",
      "PRED: Ambivalent\n"
     ]
    }
   ],
   "source": [
    "sample = test.select(range(10))\n",
    "\n",
    "for i, ex in enumerate(sample):\n",
    "    q = ex[\"question\"]\n",
    "    a = ex[\"interview_answer\"]\n",
    "    gold = ex[\"clarity_label\"]\n",
    "\n",
    "    raw = call_llm(build_prompt(q, a))\n",
    "    pred = normalize_label(raw)\n",
    "\n",
    "    print(f\"\\n--- Example {i} ---\")\n",
    "    print(\"GOLD:\", gold)\n",
    "    print(\"RAW :\", raw)\n",
    "    print(\"PRED:\", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "069cb81a-a497-4d95-a215-8d14caf4be0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:46<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.7\n",
      "Macro-F1: 0.4492784992784993\n",
      "\n",
      "Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "     Ambivalent       0.86      0.80      0.83        40\n",
      "Clear Non-Reply       0.17      0.67      0.27         3\n",
      "    Clear Reply       1.00      0.14      0.25         7\n",
      "\n",
      "       accuracy                           0.70        50\n",
      "      macro avg       0.68      0.54      0.45        50\n",
      "   weighted avg       0.84      0.70      0.72        50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "subset = test.select(range(min(50, len(test))))\n",
    "\n",
    "preds, golds, raws = [], [], []\n",
    "\n",
    "for ex in tqdm(subset):\n",
    "    q = ex[\"question\"]\n",
    "    a = ex[\"interview_answer\"]\n",
    "    gold = ex[\"clarity_label\"]\n",
    "\n",
    "    raw = call_llm(build_prompt(q, a))\n",
    "    pred = normalize_label(raw)\n",
    "\n",
    "    # One retry if the model output is not parseable\n",
    "    if pred is None:\n",
    "        raw2 = call_llm(build_prompt(q, a) + \"\\nAnswer with exactly one label. No other text.\")\n",
    "        pred = normalize_label(raw2)\n",
    "        raw = raw + \" | FALLBACK: \" + raw2\n",
    "\n",
    "    preds.append(pred)\n",
    "    golds.append(gold)\n",
    "    raws.append(raw)\n",
    "\n",
    "acc = accuracy_score(golds, preds)\n",
    "f1  = f1_score(golds, preds, average=\"macro\")\n",
    "\n",
    "print(\"ACC:\", acc)\n",
    "print(\"Macro-F1:\", f1)\n",
    "print(\"\\nReport:\\n\", classification_report(golds, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5639ecd8-cdb0-4a7d-95d5-e4ad968b26a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 308/308 [04:19<00:00,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL ACC: 0.6038961038961039\n",
      "FINAL Macro-F1: 0.43666614888071936\n",
      "\n",
      "FINAL Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "     Ambivalent       0.70      0.78      0.74       206\n",
      "Clear Non-Reply       0.21      0.61      0.31        23\n",
      "    Clear Reply       0.86      0.15      0.26        79\n",
      "\n",
      "       accuracy                           0.60       308\n",
      "      macro avg       0.59      0.51      0.44       308\n",
      "   weighted avg       0.71      0.60      0.58       308\n",
      "\n",
      "Saved: prompting_results_gpt4o-mini_zero-shot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>gold</th>\n",
       "      <th>pred</th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inquiring about the status or information reg...</td>\n",
       "      <td>Well, the world has made it clear that these t...</td>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Ambivalent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will you invite them to the White House to neg...</td>\n",
       "      <td>I think that anytime and anyplace that they ar...</td>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Ambivalent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why was it necessary for Japan to drop the thr...</td>\n",
       "      <td>I think that the purpose of the U.N. Security ...</td>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Ambivalent Reply</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When will we see this resolution?</td>\n",
       "      <td>I'll let Condi talk about the details of what ...</td>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Ambivalent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Updating the figure of Iraqi deaths</td>\n",
       "      <td>No, I don't consider it a credible report; nei...</td>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Ambivalent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0   Inquiring about the status or information reg...   \n",
       "1  Will you invite them to the White House to neg...   \n",
       "2  Why was it necessary for Japan to drop the thr...   \n",
       "3                  When will we see this resolution?   \n",
       "4                Updating the figure of Iraqi deaths   \n",
       "\n",
       "                                              answer        gold        pred  \\\n",
       "0  Well, the world has made it clear that these t...  Ambivalent  Ambivalent   \n",
       "1  I think that anytime and anyplace that they ar...  Ambivalent  Ambivalent   \n",
       "2  I think that the purpose of the U.N. Security ...  Ambivalent  Ambivalent   \n",
       "3  I'll let Condi talk about the details of what ...  Ambivalent  Ambivalent   \n",
       "4  No, I don't consider it a credible report; nei...  Ambivalent  Ambivalent   \n",
       "\n",
       "                raw  \n",
       "0        Ambivalent  \n",
       "1        Ambivalent  \n",
       "2  Ambivalent Reply  \n",
       "3        Ambivalent  \n",
       "4        Ambivalent  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, golds, raws = [], [], []\n",
    "\n",
    "for ex in tqdm(test):\n",
    "    q = ex[\"question\"]\n",
    "    a = ex[\"interview_answer\"]\n",
    "    gold = ex[\"clarity_label\"]\n",
    "\n",
    "    raw = call_llm(build_prompt(q, a))\n",
    "    pred = normalize_label(raw)\n",
    "\n",
    "    if pred is None:\n",
    "        raw2 = call_llm(build_prompt(q, a) + \"\\nAnswer with exactly one label. No other text.\")\n",
    "        pred = normalize_label(raw2)\n",
    "        raw = raw + \" | FALLBACK: \" + raw2\n",
    "\n",
    "    preds.append(pred)\n",
    "    golds.append(gold)\n",
    "    raws.append(raw)\n",
    "\n",
    "acc = accuracy_score(golds, preds)\n",
    "f1  = f1_score(golds, preds, average=\"macro\")\n",
    "\n",
    "print(\"FINAL ACC:\", acc)\n",
    "print(\"FINAL Macro-F1:\", f1)\n",
    "print(\"\\nFINAL Report:\\n\", classification_report(golds, preds))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"question\": [ex[\"question\"] for ex in test],\n",
    "    \"answer\":   [ex[\"interview_answer\"] for ex in test],\n",
    "    \"gold\": golds,\n",
    "    \"pred\": preds,\n",
    "    \"raw\": raws\n",
    "})\n",
    "\n",
    "out_path = \"prompting_results_gpt4o-mini_zero-shot.csv\"\n",
    "df.to_csv(out_path, index=False)\n",
    "print(\"Saved:\", out_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "824f9828-17a1-4009-9d93-f52dddead91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred:Clear Reply</th>\n",
       "      <th>pred:Ambivalent</th>\n",
       "      <th>pred:Clear Non-Reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gold:Clear Reply</th>\n",
       "      <td>12</td>\n",
       "      <td>59</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gold:Ambivalent</th>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gold:Clear Non-Reply</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      pred:Clear Reply  pred:Ambivalent  pred:Clear Non-Reply\n",
       "gold:Clear Reply                    12               59                     8\n",
       "gold:Ambivalent                      2              160                    44\n",
       "gold:Clear Non-Reply                 0                9                    14"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [\"Clear Reply\", \"Ambivalent\", \"Clear Non-Reply\"]\n",
    "\n",
    "cm = confusion_matrix(golds, preds, labels=labels)\n",
    "cm_df = pd.DataFrame(cm, index=[f\"gold:{l}\" for l in labels], columns=[f\"pred:{l}\" for l in labels])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af6f713a-a071-4664-9dd9-dacb02ad74e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: 122 out of 308\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold</th>\n",
       "      <th>pred</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Clear Non-Reply</td>\n",
       "      <td>Do you think the Republican leader in the Hous...</td>\n",
       "      <td>I wouldn't have exactly put it that way. But I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Clear Reply</td>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Shape of the multinational force</td>\n",
       "      <td>In terms of the troops, that's what the meetin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Clear Non-Reply</td>\n",
       "      <td>Do you see any contradictory evidence in the c...</td>\n",
       "      <td>No, I said—Mike, thanks. I was just speculatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Clear Reply</td>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>What have they achieved and what will they lea...</td>\n",
       "      <td>Okay, I will start answering. Has it become be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Clear Non-Reply</td>\n",
       "      <td>Would you campaign against Senator Joe Lieberm...</td>\n",
       "      <td>I'm going to stay out of Connecticut. []</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Clear Non-Reply</td>\n",
       "      <td>Would you veto the bill if it passes in the fo...</td>\n",
       "      <td>First, we have been working throughout the sum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Clear Reply</td>\n",
       "      <td>Clear Non-Reply</td>\n",
       "      <td>Was this coordinated with you?</td>\n",
       "      <td>No, it wasn't coordinated with me, and my pati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Clear Non-Reply</td>\n",
       "      <td>What is the outlook in your view when you will...</td>\n",
       "      <td>Well, to answer the first question, there's th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Clear Non-Reply</td>\n",
       "      <td>Do you have to take those with something of a ...</td>\n",
       "      <td>With respect to Europe, I'm deeply concerned, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Clear Reply</td>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>New Policy on Intercepting North Korean Ships</td>\n",
       "      <td>Well, this is not simply a U.S. policy; this i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Clear Reply</td>\n",
       "      <td>Clear Non-Reply</td>\n",
       "      <td>Is it no longer important to track him down?</td>\n",
       "      <td>It's just an incorrect story. I mean, we got a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Clear Non-Reply</td>\n",
       "      <td>Did Prime Minister Olmert present positions to...</td>\n",
       "      <td>[Inaudible]—what the NIE actually said. It sai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Clear Non-Reply</td>\n",
       "      <td>Other financial steps the President is prepare...</td>\n",
       "      <td>Roger, I do not comment on the decisions made ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Clear Reply</td>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Concern about financial institutions seeking i...</td>\n",
       "      <td>No, I like to get our money back. I think the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Clear Reply</td>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>How do you feel about Plan B in general?</td>\n",
       "      <td>I believe that Plan B ought to be—ought to req...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Clear Reply</td>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Addressing the desire of Cuban exiles to go ho...</td>\n",
       "      <td>First of all, Cuba is not a very transparent s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Clear Non-Reply</td>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Why wouldn't you be frustrated, sir, about wh...</td>\n",
       "      <td>I'm not—I do remember the meeting; I don't rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Clear Non-Reply</td>\n",
       "      <td>Administration's contingency plans for his death</td>\n",
       "      <td>First of all, Cuba is not a very transparent s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Clear Reply</td>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Performance of the Fed in handling the financi...</td>\n",
       "      <td>I'm not going to make news about Ben Bernanke-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Clear Reply</td>\n",
       "      <td>Clear Non-Reply</td>\n",
       "      <td>Request for permission to ask another questio...</td>\n",
       "      <td>Go ahead—he hasn't asked his question yet. I r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Clear Non-Reply</td>\n",
       "      <td>And to President Karzai, if I might, what do y...</td>\n",
       "      <td>Do you want to start? Go ahead, please. [] I, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Clear Reply</td>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Has House Speaker Hastert lost touch within h...</td>\n",
       "      <td>No, I think the Speaker's strong statements ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Clear Reply</td>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>How do you see the situation with the Iranian ...</td>\n",
       "      <td>——progress, because Russia and the United Stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Clear Reply</td>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>Are the individuals satisfied with the assuran...</td>\n",
       "      <td>Well, first of all, I appreciate the briefing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Clear Reply</td>\n",
       "      <td>Ambivalent</td>\n",
       "      <td>What did you mean by 'Third Awakening'?</td>\n",
       "      <td>No, I said—Mike, thanks. I was just speculatin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               gold             pred  \\\n",
       "5        Ambivalent  Clear Non-Reply   \n",
       "11      Clear Reply       Ambivalent   \n",
       "12       Ambivalent  Clear Non-Reply   \n",
       "13      Clear Reply       Ambivalent   \n",
       "17       Ambivalent  Clear Non-Reply   \n",
       "18       Ambivalent  Clear Non-Reply   \n",
       "21      Clear Reply  Clear Non-Reply   \n",
       "25       Ambivalent  Clear Non-Reply   \n",
       "27       Ambivalent  Clear Non-Reply   \n",
       "30      Clear Reply       Ambivalent   \n",
       "36      Clear Reply  Clear Non-Reply   \n",
       "41       Ambivalent  Clear Non-Reply   \n",
       "43       Ambivalent  Clear Non-Reply   \n",
       "46      Clear Reply       Ambivalent   \n",
       "51      Clear Reply       Ambivalent   \n",
       "54      Clear Reply       Ambivalent   \n",
       "56  Clear Non-Reply       Ambivalent   \n",
       "57       Ambivalent  Clear Non-Reply   \n",
       "58      Clear Reply       Ambivalent   \n",
       "60      Clear Reply  Clear Non-Reply   \n",
       "62       Ambivalent  Clear Non-Reply   \n",
       "63      Clear Reply       Ambivalent   \n",
       "66      Clear Reply       Ambivalent   \n",
       "67      Clear Reply       Ambivalent   \n",
       "69      Clear Reply       Ambivalent   \n",
       "\n",
       "                                             question  \\\n",
       "5   Do you think the Republican leader in the Hous...   \n",
       "11                   Shape of the multinational force   \n",
       "12  Do you see any contradictory evidence in the c...   \n",
       "13  What have they achieved and what will they lea...   \n",
       "17  Would you campaign against Senator Joe Lieberm...   \n",
       "18  Would you veto the bill if it passes in the fo...   \n",
       "21                     Was this coordinated with you?   \n",
       "25  What is the outlook in your view when you will...   \n",
       "27  Do you have to take those with something of a ...   \n",
       "30      New Policy on Intercepting North Korean Ships   \n",
       "36       Is it no longer important to track him down?   \n",
       "41  Did Prime Minister Olmert present positions to...   \n",
       "43  Other financial steps the President is prepare...   \n",
       "46  Concern about financial institutions seeking i...   \n",
       "51           How do you feel about Plan B in general?   \n",
       "54  Addressing the desire of Cuban exiles to go ho...   \n",
       "56   Why wouldn't you be frustrated, sir, about wh...   \n",
       "57   Administration's contingency plans for his death   \n",
       "58  Performance of the Fed in handling the financi...   \n",
       "60   Request for permission to ask another questio...   \n",
       "62  And to President Karzai, if I might, what do y...   \n",
       "63   Has House Speaker Hastert lost touch within h...   \n",
       "66  How do you see the situation with the Iranian ...   \n",
       "67  Are the individuals satisfied with the assuran...   \n",
       "69            What did you mean by 'Third Awakening'?   \n",
       "\n",
       "                                               answer  \n",
       "5   I wouldn't have exactly put it that way. But I...  \n",
       "11  In terms of the troops, that's what the meetin...  \n",
       "12  No, I said—Mike, thanks. I was just speculatin...  \n",
       "13  Okay, I will start answering. Has it become be...  \n",
       "17           I'm going to stay out of Connecticut. []  \n",
       "18  First, we have been working throughout the sum...  \n",
       "21  No, it wasn't coordinated with me, and my pati...  \n",
       "25  Well, to answer the first question, there's th...  \n",
       "27  With respect to Europe, I'm deeply concerned, ...  \n",
       "30  Well, this is not simply a U.S. policy; this i...  \n",
       "36  It's just an incorrect story. I mean, we got a...  \n",
       "41  [Inaudible]—what the NIE actually said. It sai...  \n",
       "43  Roger, I do not comment on the decisions made ...  \n",
       "46  No, I like to get our money back. I think the ...  \n",
       "51  I believe that Plan B ought to be—ought to req...  \n",
       "54  First of all, Cuba is not a very transparent s...  \n",
       "56  I'm not—I do remember the meeting; I don't rem...  \n",
       "57  First of all, Cuba is not a very transparent s...  \n",
       "58  I'm not going to make news about Ben Bernanke-...  \n",
       "60  Go ahead—he hasn't asked his question yet. I r...  \n",
       "62  Do you want to start? Go ahead, please. [] I, ...  \n",
       "63  No, I think the Speaker's strong statements ha...  \n",
       "66  ——progress, because Russia and the United Stat...  \n",
       "67  Well, first of all, I appreciate the briefing ...  \n",
       "69  No, I said—Mike, thanks. I was just speculatin...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = df[df[\"gold\"] != df[\"pred\"]].copy()\n",
    "print(\"Errors:\", len(errors), \"out of\", len(df))\n",
    "\n",
    "# Show a few mistakes (useful for analysis)\n",
    "errors.head(25)[[\"gold\", \"pred\", \"question\", \"answer\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e396519f-54ca-4cd8-85c2-c0cabd5c4c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LABEL: Ambivalent\n",
      "Q: Leverage to stop Assad and Putin in Aleppo\n",
      "A: One of the great things about our democracy is, it expresses itself in all sorts of ways, and that includes people prote\n",
      "\n",
      "LABEL: Clear Reply\n",
      "Q:  What was the message you were trying to send with not only your decision not to attend the Sochi Games, but also with t\n",
      "A: Well, first of all, I haven't attended Olympics in the past, and I suspect that me attending the Olympics, particularly \n",
      "\n",
      "LABEL: Ambivalent\n",
      "Q:  Is there any point at which the United States would consider arming the rebels?\n",
      "A: I was one of the first leaders, I think, around the world to say Asad had to go, in response to the incredible brutality\n",
      "\n",
      "LABEL: Clear Non-Reply\n",
      "Q: Request for confirmation of drone strikes in Yemen.\n",
      "A: I will not have a discussion about operational issues.Ed Henry [FOX News].\n",
      "\n",
      "LABEL: Clear Reply\n",
      "Q: And could this signal your real losses for Democrats in the midterms?\n",
      "A: We're going to win. I think we're going to win in Virginia.And you know—you're reporting it being close—the race is very\n",
      "\n",
      "LABEL: Clear Non-Reply\n",
      "Q:  Does the deal meet your requirements in terms of national security concerns?\n",
      "A: Okay, they're giving me studies on the deal. It has to be a hundred percent as far as national security is concerned. An\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "train_df = pd.DataFrame(train)\n",
    "\n",
    "shots = []\n",
    "for label in [\"Clear Reply\", \"Ambivalent\", \"Clear Non-Reply\"]:\n",
    "    candidates = train_df[train_df[\"clarity_label\"] == label]\n",
    "    # pick random rows\n",
    "    sampled = candidates.sample(2, random_state=42).to_dict(\"records\")\n",
    "    shots.extend(sampled)\n",
    "\n",
    "# shuffle so model doesn't learn ordering bias\n",
    "random.shuffle(shots)\n",
    "\n",
    "# Show what got selected (sanity)\n",
    "for s in shots:\n",
    "    print(\"\\nLABEL:\", s[\"clarity_label\"])\n",
    "    print(\"Q:\", s[\"question\"][:120])\n",
    "    print(\"A:\", s[\"interview_answer\"][:120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddff9da6-442a-468e-95df-0a2d61e6d339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fewshot_prompt(shots, question, answer):\n",
    "    \"\"\"\n",
    "    Few-shot prompt using labeled examples from the training split.\n",
    "    \"\"\"\n",
    "    examples_block = \"\"\n",
    "    for ex in shots:\n",
    "        examples_block += (\n",
    "            f\"Question: {ex['question']}\\n\"\n",
    "            f\"Answer: {ex['interview_answer']}\\n\"\n",
    "            f\"Label: {ex['clarity_label']}\\n\\n\"\n",
    "        )\n",
    "\n",
    "    return f\"\"\"You are an expert political discourse analyst.\n",
    "\n",
    "Task: classify the clarity of a politician's answer to the given question.\n",
    "\n",
    "Labels:\n",
    "- Clear Reply: directly answers the question unambiguously.\n",
    "- Ambivalent: appears relevant but is vague/hedged/multi-interpretable or partially answers.\n",
    "- Clear Non-Reply: refuses to answer or does not address the question.\n",
    "\n",
    "Here are labeled examples:\n",
    "{examples_block}\n",
    "Now classify this pair.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "{answer}\n",
    "\n",
    "Return ONLY one label from:\n",
    "Clear Reply, Ambivalent, Clear Non-Reply\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb58310b-2483-45e7-bafd-c701c51550f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 308/308 [04:38<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEW-SHOT ACC: 0.6883116883116883\n",
      "FEW-SHOT Macro-F1: 0.5605262551210403\n",
      "\n",
      "FEW-SHOT Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "     Ambivalent       0.75      0.83      0.79       206\n",
      "Clear Non-Reply       0.38      0.48      0.42        23\n",
      "    Clear Reply       0.60      0.39      0.47        79\n",
      "\n",
      "       accuracy                           0.69       308\n",
      "      macro avg       0.57      0.57      0.56       308\n",
      "   weighted avg       0.68      0.69      0.68       308\n",
      "\n",
      "Saved: prompting_results_gpt4o-mini_few-shot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds_fs, golds_fs, raws_fs = [], [], []\n",
    "\n",
    "for ex in tqdm(test):\n",
    "    q = ex[\"question\"]\n",
    "    a = ex[\"interview_answer\"]\n",
    "    gold = ex[\"clarity_label\"]\n",
    "\n",
    "    prompt = build_fewshot_prompt(shots, q, a)\n",
    "    raw = call_llm(prompt)\n",
    "    pred = normalize_label(raw)\n",
    "\n",
    "    if pred is None:\n",
    "        raw2 = call_llm(prompt + \"\\nAnswer with exactly one label. No other text.\")\n",
    "        pred = normalize_label(raw2)\n",
    "        raw = raw + \" | FALLBACK: \" + raw2\n",
    "\n",
    "    # final clamp (avoid None messing metrics)\n",
    "    if pred is None:\n",
    "        pred = \"Ambivalent\"\n",
    "\n",
    "    preds_fs.append(pred)\n",
    "    golds_fs.append(gold)\n",
    "    raws_fs.append(raw)\n",
    "\n",
    "acc_fs = accuracy_score(golds_fs, preds_fs)\n",
    "f1_fs  = f1_score(golds_fs, preds_fs, average=\"macro\")\n",
    "\n",
    "print(\"FEW-SHOT ACC:\", acc_fs)\n",
    "print(\"FEW-SHOT Macro-F1:\", f1_fs)\n",
    "print(\"\\nFEW-SHOT Report:\\n\", classification_report(golds_fs, preds_fs))\n",
    "\n",
    "df_fs = pd.DataFrame({\n",
    "    \"question\": [ex[\"question\"] for ex in test],\n",
    "    \"answer\":   [ex[\"interview_answer\"] for ex in test],\n",
    "    \"gold\": golds_fs,\n",
    "    \"pred\": preds_fs,\n",
    "    \"raw\": raws_fs\n",
    "})\n",
    "out_path = \"prompting_results_gpt4o-mini_few-shot.csv\"\n",
    "df_fs.to_csv(out_path, index=False)\n",
    "print(\"Saved:\", out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
